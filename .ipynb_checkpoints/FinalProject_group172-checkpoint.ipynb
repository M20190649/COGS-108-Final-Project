{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emissions from vehicles have been adding to the everlasting modern-day problems of air pollution and traffic. The introduction of electric vehicles along with a greater emphasis placed on walking, biking, and/or using micro-mobility resources for transportation has reduced the impact to the growing gas emission problem as well as traffic congestion. However, there is still a reliance on vehicles to get people to their destinations, which is what rideshare services alleviate. These programs allow for multiple people to join a ride going in a similar destination, serving as a carpool, which saves gas, time, and money. \n",
    "\n",
    "Many people have contemplated either buying a car or just continuing to use rideshare options, especially when Uber and Lyft constantly promote their services with discount codes. New vehicles cost tens of thousand dollars, and research shows that cars are not even used 95% of the time(Barter). On average, a car is in usage for 6 out of the 168 hours of the week. This number is so small and on top of that the cost of owning a car continues to increase because of the maintenance, insurance, and the possibility of crashes. \n",
    "\n",
    "Rideshare programs such as Uber and Lyft are almost ubiquitous in our modern day world. Studies have shown that rideshare services have increased 37% from 1.9 billion to 2.61 billion people from 2016 to 2017. Both Uber and Lyft claim that one of their driving principles revolves around reducing traffic congestion through minimizing car ownership and usage. In urban cities such as San Francisco, Los Angeles and New York, analyzing peak commute times would prove to be a sound indicator of whether these companies are alleviating the flow of traffic.  \n",
    "\n",
    "To investigate, we would analyze accumulated data about traffic patterns during peak commute times in densely populated cities since the onset of rideshare popularity. We would also look at specific usage trends with regards to rideshare program data to draw correlations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Brendan Wong\n",
    "- Pooja Yadav\n",
    "- Kaila Lee\n",
    "- Rajandeep Kaur\n",
    "- Zoey Chesny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members IDs\n",
    "\n",
    "- A15749312\n",
    "- A13997099\n",
    "- A12792644\n",
    "- A13736425\n",
    "- A13303136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To what extent do rideshare programs (e.g. Uber, Lyft) impact traffic during peak commute times? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer our research question and hypothesis, we'll be using Uber's Movement dataset to compare traffic and commute times on weekdays to that of DataSF's back before ridesharing was widespread. \n",
    "\n",
    "or\n",
    "\n",
    "To answer our research question and hypothesis, we'll be using Uber's Movement dataset to compare traffic and commute times on weekdays between 2016 and 2018. Just from 2016 to 2017 alone, there was a 37% increase of use in rideshare services so there would be a big enough discrepancy to determine increase or decrease of traffic\n",
    "\n",
    "References (include links):\n",
    "- 1)\n",
    "- 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your hypotheses here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your dataset information here*\n",
    "\n",
    "(Copy this information for each dataset)\n",
    "- Dataset Name:\n",
    "- Link to the dataset:\n",
    "- Number of observations:\n",
    "\n",
    "1-2 sentences describing each dataset. \n",
    "\n",
    "If you plan to use multiple datasets, add 1-2 sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Most of our data was pulled from [Uber's Movement Dataset](https://movement.uber.com/?lang=en-US). Each row is the aggregated mean and standard deviation of travel time and geometric travel time over the course of each quarter in the fiscal year. At the start of the project, quarter 1 of 2016 through quarter 3 of 2018 were available. Sources and destinations are determined by 'sourceid' and 'dstid'. We decided to choose the inner join of sources and destinations with over 10,000 rows as a source, and 5,000 as a destination. Furthermore we'd be tracking commute times so we'd be further filtering from rush hour in the Bay Area, all the time in San Francisco, but typically 7am - 10am and 3pm - 7pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9613339, 7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "#Display plots directly in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 2018 quarter 3 weekdays\n",
    "# will need to download separately and store in working dir\n",
    "q3_2018_location = 'san_francisco-censustracts-2018-3-OnlyWeekdays-HourlyAggregate.csv'\n",
    "\n",
    "uber_df = pd.read_csv(q3_2018_location)\n",
    "uber_df.shape\n",
    "# set contains almost 10 million rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>dstid</th>\n",
       "      <th>hod</th>\n",
       "      <th>mean_travel_time</th>\n",
       "      <th>standard_deviation_travel_time</th>\n",
       "      <th>geometric_mean_travel_time</th>\n",
       "      <th>geometric_standard_deviation_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4806669</th>\n",
       "      <td>1498</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>387.64</td>\n",
       "      <td>165.81</td>\n",
       "      <td>363.88</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732148</th>\n",
       "      <td>1742</td>\n",
       "      <td>1743</td>\n",
       "      <td>0</td>\n",
       "      <td>594.00</td>\n",
       "      <td>216.39</td>\n",
       "      <td>532.56</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732147</th>\n",
       "      <td>1743</td>\n",
       "      <td>1733</td>\n",
       "      <td>0</td>\n",
       "      <td>1319.04</td>\n",
       "      <td>326.51</td>\n",
       "      <td>1284.17</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732146</th>\n",
       "      <td>1772</td>\n",
       "      <td>1443</td>\n",
       "      <td>0</td>\n",
       "      <td>760.37</td>\n",
       "      <td>251.59</td>\n",
       "      <td>723.62</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281306</th>\n",
       "      <td>629</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>1102.59</td>\n",
       "      <td>329.58</td>\n",
       "      <td>1061.21</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sourceid  dstid  hod  mean_travel_time  \\\n",
       "4806669      1498   1069    0            387.64   \n",
       "2732148      1742   1743    0            594.00   \n",
       "2732147      1743   1733    0           1319.04   \n",
       "2732146      1772   1443    0            760.37   \n",
       "5281306       629     96    0           1102.59   \n",
       "\n",
       "         standard_deviation_travel_time  geometric_mean_travel_time  \\\n",
       "4806669                          165.81                      363.88   \n",
       "2732148                          216.39                      532.56   \n",
       "2732147                          326.51                     1284.17   \n",
       "2732146                          251.59                      723.62   \n",
       "5281306                          329.58                     1061.21   \n",
       "\n",
       "         geometric_standard_deviation_travel_time  \n",
       "4806669                                      1.39  \n",
       "2732148                                      1.83  \n",
       "2732147                                      1.25  \n",
       "2732146                                      1.36  \n",
       "5281306                                      1.31  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by hours of the day \n",
    "uber_df.sort_values('hod').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(436433, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "for root, dirs, files in os.walk(\"/Users/brendanwong/Desktop/DATACLEANUP\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = root +\"/\"+ file\n",
    "            df = pd.read_csv(path)\n",
    "            print(file + \" shape: \" + str(df.shape))\n",
    "            \n",
    "            df.sort_values('hod')\n",
    "            df['sourceid'].value_counts();\n",
    "            sources = df['sourceid'].value_counts() < 6000;\n",
    "            sources = sources.reset_index()\n",
    "            \n",
    "            for index, items in sources.iterrows():\n",
    "                if not items['sourceid']:\n",
    "                    sources.drop(index, inplace=True)\n",
    "            \n",
    "            print(\"sources shape: \" + str(sources.shape))\n",
    "            \n",
    "            for index, items in sources.iterrows():\n",
    "                df = df[df.sourceid != items['index']]\n",
    "                \n",
    "            print(file + \" shape: \" + str(df.shape))\n",
    "            \n",
    "            df['dstid'].value_counts()\n",
    "            destinations = df['dstid'].value_counts() < 3500\n",
    "            destinations = destinations.reset_index()\n",
    "            \n",
    "            for index, items in destinations.iterrows():\n",
    "                if not items['dstid']:\n",
    "                    destinations.drop(index, inplace=True)\n",
    "            \n",
    "            print(\"destinations shape: \" + str(destinations.shape))\n",
    "            \n",
    "            for index, items in destinations.iterrows():\n",
    "                df = df[df.dstid != items['index']]\n",
    "            \n",
    "            print(file + \" shape: \" + str(df.shape))\n",
    "            \n",
    "            hours = [0,1,2,3,4,5,6,11,12,13,14,20,21,22,23,24]\n",
    "            \n",
    "            for hour in hours:\n",
    "                df = df[df.hod != hour]\n",
    "                \n",
    "            print(file + \" shape: \" + str(df.shape))\n",
    "            \n",
    "            df.to_csv(\"filtered_\" + file)\n",
    "            print(\"FILTERED SHAPE: \" + str(df.shape))\n",
    "            print(\"\\n\\n\")\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(\"time:\\n\\n\\n\\n\")\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe your data cleaning steps here.\n",
    "\n",
    "1) Check for missing values \n",
    "\n",
    "2) Consolidate dataset \n",
    "\n",
    "\n",
    "* We want to see the trends of how uber usage increases over time and compare it to commute times\n",
    "* exclude data that has small travel times to account for \n",
    "* dropped geometric travel time because we only care about arithmatic one\n",
    "* travel time is given in seconds \n",
    "\n",
    "\n",
    "1) Determine peak travel hour of days \n",
    "\n",
    "2) How do mean times change from 2016 to 2018\n",
    "\n",
    "3) pool from other sources to count the number of trips \n",
    "\n",
    "4) find common sources and destinations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 4 most popular sources\n",
      "234     27446\n",
      "2231    24946\n",
      "2308    23853\n",
      "2622    22913\n",
      "Name: sourceid, dtype: int64\n",
      "top 4 most popular destinations\n",
      "234     28851\n",
      "2308    24107\n",
      "2622    23773\n",
      "1743    23283\n",
      "Name: dstid, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>dstid</th>\n",
       "      <th>hod</th>\n",
       "      <th>mean_travel_time</th>\n",
       "      <th>standard_deviation_travel_time</th>\n",
       "      <th>geometric_mean_travel_time</th>\n",
       "      <th>geometric_standard_deviation_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170905</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>16</td>\n",
       "      <td>1999.96</td>\n",
       "      <td>432.27</td>\n",
       "      <td>1958.11</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395424</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>1</td>\n",
       "      <td>1239.74</td>\n",
       "      <td>297.00</td>\n",
       "      <td>1209.41</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965293</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>19</td>\n",
       "      <td>1601.99</td>\n",
       "      <td>368.42</td>\n",
       "      <td>1564.73</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052223</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>21</td>\n",
       "      <td>1493.69</td>\n",
       "      <td>363.41</td>\n",
       "      <td>1455.92</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648827</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>22</td>\n",
       "      <td>1440.61</td>\n",
       "      <td>368.82</td>\n",
       "      <td>1401.86</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759455</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>23</td>\n",
       "      <td>1358.48</td>\n",
       "      <td>328.82</td>\n",
       "      <td>1324.88</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481985</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1209.66</td>\n",
       "      <td>302.77</td>\n",
       "      <td>1179.36</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211751</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>10</td>\n",
       "      <td>1555.40</td>\n",
       "      <td>307.67</td>\n",
       "      <td>1530.10</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683372</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>18</td>\n",
       "      <td>1847.22</td>\n",
       "      <td>419.36</td>\n",
       "      <td>1803.84</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984378</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>6</td>\n",
       "      <td>1310.33</td>\n",
       "      <td>229.34</td>\n",
       "      <td>1293.24</td>\n",
       "      <td>1.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338752</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>15</td>\n",
       "      <td>1839.97</td>\n",
       "      <td>411.53</td>\n",
       "      <td>1801.26</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471555</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>17</td>\n",
       "      <td>2199.42</td>\n",
       "      <td>504.89</td>\n",
       "      <td>2146.90</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926262</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>7</td>\n",
       "      <td>1564.26</td>\n",
       "      <td>309.72</td>\n",
       "      <td>1537.37</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5319224</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>9</td>\n",
       "      <td>1663.29</td>\n",
       "      <td>330.44</td>\n",
       "      <td>1633.45</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885086</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>4</td>\n",
       "      <td>1193.39</td>\n",
       "      <td>219.14</td>\n",
       "      <td>1176.18</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6290912</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>14</td>\n",
       "      <td>1751.33</td>\n",
       "      <td>351.44</td>\n",
       "      <td>1719.72</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064170</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>11</td>\n",
       "      <td>1538.31</td>\n",
       "      <td>288.82</td>\n",
       "      <td>1514.52</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7509069</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>12</td>\n",
       "      <td>1570.93</td>\n",
       "      <td>320.43</td>\n",
       "      <td>1543.30</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7707866</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>5</td>\n",
       "      <td>1172.69</td>\n",
       "      <td>194.82</td>\n",
       "      <td>1158.70</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7902439</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>8</td>\n",
       "      <td>1723.92</td>\n",
       "      <td>390.04</td>\n",
       "      <td>1686.41</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8292392</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>20</td>\n",
       "      <td>1530.56</td>\n",
       "      <td>359.58</td>\n",
       "      <td>1495.58</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8655777</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>2</td>\n",
       "      <td>1210.92</td>\n",
       "      <td>230.45</td>\n",
       "      <td>1191.37</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256509</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>3</td>\n",
       "      <td>1267.13</td>\n",
       "      <td>280.42</td>\n",
       "      <td>1242.60</td>\n",
       "      <td>1.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9578408</th>\n",
       "      <td>963</td>\n",
       "      <td>234</td>\n",
       "      <td>13</td>\n",
       "      <td>1627.42</td>\n",
       "      <td>351.11</td>\n",
       "      <td>1595.60</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sourceid  dstid  hod  mean_travel_time  \\\n",
       "170905        963    234   16           1999.96   \n",
       "395424        963    234    1           1239.74   \n",
       "965293        963    234   19           1601.99   \n",
       "1052223       963    234   21           1493.69   \n",
       "1648827       963    234   22           1440.61   \n",
       "1759455       963    234   23           1358.48   \n",
       "2481985       963    234    0           1209.66   \n",
       "3211751       963    234   10           1555.40   \n",
       "3683372       963    234   18           1847.22   \n",
       "3984378       963    234    6           1310.33   \n",
       "4338752       963    234   15           1839.97   \n",
       "4471555       963    234   17           2199.42   \n",
       "4926262       963    234    7           1564.26   \n",
       "5319224       963    234    9           1663.29   \n",
       "5885086       963    234    4           1193.39   \n",
       "6290912       963    234   14           1751.33   \n",
       "7064170       963    234   11           1538.31   \n",
       "7509069       963    234   12           1570.93   \n",
       "7707866       963    234    5           1172.69   \n",
       "7902439       963    234    8           1723.92   \n",
       "8292392       963    234   20           1530.56   \n",
       "8655777       963    234    2           1210.92   \n",
       "9256509       963    234    3           1267.13   \n",
       "9578408       963    234   13           1627.42   \n",
       "\n",
       "         standard_deviation_travel_time  geometric_mean_travel_time  \\\n",
       "170905                           432.27                     1958.11   \n",
       "395424                           297.00                     1209.41   \n",
       "965293                           368.42                     1564.73   \n",
       "1052223                          363.41                     1455.92   \n",
       "1648827                          368.82                     1401.86   \n",
       "1759455                          328.82                     1324.88   \n",
       "2481985                          302.77                     1179.36   \n",
       "3211751                          307.67                     1530.10   \n",
       "3683372                          419.36                     1803.84   \n",
       "3984378                          229.34                     1293.24   \n",
       "4338752                          411.53                     1801.26   \n",
       "4471555                          504.89                     2146.90   \n",
       "4926262                          309.72                     1537.37   \n",
       "5319224                          330.44                     1633.45   \n",
       "5885086                          219.14                     1176.18   \n",
       "6290912                          351.44                     1719.72   \n",
       "7064170                          288.82                     1514.52   \n",
       "7509069                          320.43                     1543.30   \n",
       "7707866                          194.82                     1158.70   \n",
       "7902439                          390.04                     1686.41   \n",
       "8292392                          359.58                     1495.58   \n",
       "8655777                          230.45                     1191.37   \n",
       "9256509                          280.42                     1242.60   \n",
       "9578408                          351.11                     1595.60   \n",
       "\n",
       "         geometric_standard_deviation_travel_time  \n",
       "170905                                       1.22  \n",
       "395424                                       1.24  \n",
       "965293                                       1.24  \n",
       "1052223                                      1.25  \n",
       "1648827                                      1.25  \n",
       "1759455                                      1.24  \n",
       "2481985                                      1.24  \n",
       "3211751                                      1.19  \n",
       "3683372                                      1.24  \n",
       "3984378                                      1.17  \n",
       "4338752                                      1.22  \n",
       "4471555                                      1.24  \n",
       "4926262                                      1.20  \n",
       "5319224                                      1.21  \n",
       "5885086                                      1.18  \n",
       "6290912                                      1.21  \n",
       "7064170                                      1.19  \n",
       "7509069                                      1.20  \n",
       "7707866                                      1.16  \n",
       "7902439                                      1.23  \n",
       "8292392                                      1.23  \n",
       "8655777                                      1.19  \n",
       "9256509                                      1.21  \n",
       "9578408                                      1.22  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GOAL: find 4 most popular travel routes\n",
    "\n",
    "num_sources = uber_df['sourceid'].value_counts()\n",
    "num_dest = uber_df['dstid'].value_counts()\n",
    "\n",
    "# find most popular routes based on sources and destinations \n",
    "# 4 most popular sources: \n",
    "pop_4_sources = num_sources[:4]\n",
    "pop_4_dest = num_dest[:4]\n",
    "print('top 4 most popular sources')\n",
    "print(pop_4_sources)\n",
    "\n",
    "# 4 most popular destinations: \n",
    "print('top 4 most popular destinations')\n",
    "print(pop_4_dest)\n",
    "\n",
    "# check if a route exists between them\n",
    "uber_df[uber_df['sourceid'] == 963][uber_df['dstid'] == 234]\n",
    "\n",
    "# check if these popular routes are in all the datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 4 most popular routes are from the following sources --> destinations. \n",
    "\n",
    "| popularity rank| source | destination  |\n",
    "|---|---|---|\n",
    "|1   |963   |234 |\n",
    "|2   |212   |2622|\n",
    "|3   |457   |2231|\n",
    "|4   |532   |2308|\n",
    "\n",
    "These routes were selected since they were from the most 4 most popular source cities to the 4 most popular destination cities.\n",
    "\n",
    "A good question to ask- why are there more most popular destinations than sources?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the other datasets \n",
    "\n",
    "# 2018 quarter 3 weekdays\n",
    "# will need to download separately and store in working dir\n",
    "q1_2016_location = 'san_francisco-censustracts-2016-1-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q2_2016_location = 'san_francisco-censustracts-2016-2-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q3_2016_location = 'san_francisco-censustracts-2016-3-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q4_2016_location = 'san_francisco-censustracts-2016-4-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q1_2017_location = 'san_francisco-censustracts-2017-1-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q2_2017_location = 'san_francisco-censustracts-2017-2-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q3_2017_location = 'san_francisco-censustracts-2017-3-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q4_2017_location = 'san_francisco-censustracts-2017-4-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q1_2018_location = 'san_francisco-censustracts-2018-1-OnlyWeekdays-HourlyAggregate.csv'\n",
    "q2_2018_location = 'san_francisco-censustracts-2018-2-OnlyWeekdays-HourlyAggregate.csv'\n",
    "\n",
    "# read in all the csv files from the previous 10 quarters\n",
    "uber_df_1 = pd.read_csv(q1_2016_location)\n",
    "uber_df_2 = pd.read_csv(q2_2016_location)\n",
    "uber_df_3 = pd.read_csv(q3_2016_location)\n",
    "uber_df_4 = pd.read_csv(q4_2016_location)\n",
    "uber_df_5 = pd.read_csv(q1_2017_location)\n",
    "uber_df_6 = pd.read_csv(q2_2017_location)\n",
    "uber_df_7 = pd.read_csv(q3_2017_location)\n",
    "uber_df_8 = pd.read_csv(q4_2017_location)\n",
    "uber_df_9 = pd.read_csv(q1_2018_location)\n",
    "uber_df_10 = pd.read_csv(q2_2018_location)\n",
    "uber_df_11 = pd.read_csv(q3_2018_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# check if a route exists in each data frame \n",
    "\n",
    "# 1st most popular route is route 1 from 963 --> 234 \n",
    "df1_route1 = uber_df_1[uber_df_1['sourceid'] == 963][uber_df_1['dstid'] == 234]\n",
    "df1_route1['quarter'] = 'Q116'\n",
    "df2_route1 = uber_df_2[uber_df_2['sourceid'] == 963][uber_df_2['dstid'] == 234]\n",
    "df2_route1['quarter'] = 'Q216'\n",
    "df3_route1 = uber_df_3[uber_df_3['sourceid'] == 963][uber_df_3['dstid'] == 234]\n",
    "df3_route1['quarter'] = 'Q316'\n",
    "df4_route1 = uber_df_4[uber_df_4['sourceid'] == 963][uber_df_4['dstid'] == 234]\n",
    "df4_route1['quarter'] = 'Q416'\n",
    "df5_route1 = uber_df_5[uber_df_5['sourceid'] == 963][uber_df_5['dstid'] == 234]\n",
    "df5_route1['quarter'] = 'Q117'\n",
    "df6_route1 = uber_df_6[uber_df_6['sourceid'] == 963][uber_df_6['dstid'] == 234]\n",
    "df6_route1['quarter'] = 'Q217'\n",
    "df7_route1 = uber_df_7[uber_df_7['sourceid'] == 963][uber_df_7['dstid'] == 234]\n",
    "df7_route1['quarter'] = 'Q317'\n",
    "df8_route1 = uber_df_8[uber_df_8['sourceid'] == 963][uber_df_8['dstid'] == 234]\n",
    "df8_route1['quarter'] = 'Q417'\n",
    "df9_route1 = uber_df_9[uber_df_9['sourceid'] == 963][uber_df_9['dstid'] == 234]\n",
    "df9_route1['quarter'] = 'Q118'\n",
    "df10_route1 = uber_df_10[uber_df_10['sourceid'] == 963][uber_df_10['dstid'] == 234]\n",
    "df10_route1['quarter'] = 'Q218'\n",
    "df11_route1 = uber_df_11[uber_df_11['sourceid'] == 963][uber_df_11['dstid'] == 234]\n",
    "df11_route1['quarter'] = 'Q318'\n",
    "\n",
    "# condensed uber datasets (containing only the most popular route)\n",
    "dfs_route_1 = [df1_route1, df2_route1, df3_route1, df4_route1, df5_route1, df6_route1, df7_route1, df8_route1, df9_route1, df10_route1, df11_route1]\n",
    "\n",
    "# 2nd most popular route is route 2 from 212 --> 2622\n",
    "s = 212\n",
    "d = 2622\n",
    "df1_route2 = uber_df_1[uber_df_1['sourceid'] == s][uber_df_1['dstid'] == d]\n",
    "df1_route2['quarter'] = 'Q116'\n",
    "df2_route2 = uber_df_2[uber_df_2['sourceid'] == s][uber_df_2['dstid'] == d]\n",
    "df2_route2['quarter'] = 'Q216'\n",
    "df3_route2 = uber_df_3[uber_df_3['sourceid'] == s][uber_df_3['dstid'] == d]\n",
    "df3_route2['quarter'] = 'Q316'\n",
    "df4_route2 = uber_df_4[uber_df_4['sourceid'] == s][uber_df_4['dstid'] == d]\n",
    "df4_route2['quarter'] = 'Q416'\n",
    "df5_route2 = uber_df_5[uber_df_5['sourceid'] == s][uber_df_5['dstid'] == d]\n",
    "df5_route2['quarter'] = 'Q117'\n",
    "df6_route2 = uber_df_6[uber_df_6['sourceid'] == s][uber_df_6['dstid'] == d]\n",
    "df6_route2['quarter'] = 'Q217'\n",
    "df7_route2 = uber_df_7[uber_df_7['sourceid'] == s][uber_df_7['dstid'] == d]\n",
    "df7_route2['quarter'] = 'Q317'\n",
    "df8_route2 = uber_df_8[uber_df_8['sourceid'] == s][uber_df_8['dstid'] == d]\n",
    "df8_route2['quarter'] = 'Q417'\n",
    "df9_route2 = uber_df_9[uber_df_9['sourceid'] == s][uber_df_9['dstid'] == d]\n",
    "df9_route2['quarter'] = 'Q118'\n",
    "df10_route2 = uber_df_10[uber_df_10['sourceid'] == s][uber_df_10['dstid'] == d]\n",
    "df10_route2['quarter'] = 'Q218'\n",
    "df11_route2 = uber_df_11[uber_df_11['sourceid'] == d][uber_df_11['dstid'] == d]\n",
    "df11_route2['quarter'] = 'Q318'\n",
    "\n",
    "# condensed uber datasets (containing only the most popular route)\n",
    "dfs_route_2 = [df1_route2, df2_route2, df3_route2, df4_route2, df5_route2, df6_route2, df7_route2, df8_route2, df9_route2, df10_route2, df11_route2]\n",
    "\n",
    "# 3rd most popular route is route 2 from 457 --> 2231\n",
    "s = 457\n",
    "d = 2231\n",
    "df1_route3 = uber_df_1[uber_df_1['sourceid'] == s][uber_df_1['dstid'] == d]\n",
    "df1_route3['quarter'] = 'Q116'\n",
    "df2_route3 = uber_df_2[uber_df_2['sourceid'] == s][uber_df_2['dstid'] == d]\n",
    "df2_route3['quarter'] = 'Q216'\n",
    "df3_route3 = uber_df_3[uber_df_3['sourceid'] == s][uber_df_3['dstid'] == d]\n",
    "df3_route3['quarter'] = 'Q316'\n",
    "df4_route3 = uber_df_4[uber_df_4['sourceid'] == s][uber_df_4['dstid'] == d]\n",
    "df4_route3['quarter'] = 'Q416'\n",
    "df5_route3 = uber_df_5[uber_df_5['sourceid'] == s][uber_df_5['dstid'] == d]\n",
    "df5_route3['quarter'] = 'Q117'\n",
    "df6_route3 = uber_df_6[uber_df_6['sourceid'] == s][uber_df_6['dstid'] == d]\n",
    "df6_route3['quarter'] = 'Q217'\n",
    "df7_route3 = uber_df_7[uber_df_7['sourceid'] == s][uber_df_7['dstid'] == d]\n",
    "df7_route3['quarter'] = 'Q317'\n",
    "df8_route3 = uber_df_8[uber_df_8['sourceid'] == s][uber_df_8['dstid'] == d]\n",
    "df8_route3['quarter'] = 'Q417'\n",
    "df9_route3 = uber_df_9[uber_df_9['sourceid'] == s][uber_df_9['dstid'] == d]\n",
    "df9_route3['quarter'] = 'Q118'\n",
    "df10_route3 = uber_df_10[uber_df_10['sourceid'] == s][uber_df_10['dstid'] == d]\n",
    "df10_route3['quarter'] = 'Q218'\n",
    "df11_route3 = uber_df_11[uber_df_11['sourceid'] == d][uber_df_11['dstid'] == d]\n",
    "df11_route3['quarter'] = 'Q318'\n",
    "\n",
    "# condensed uber datasets (containing only the most popular route)\n",
    "dfs_route_3 = [df1_route3, df2_route3, df3_route3, df4_route3, df5_route3, df6_route3, df7_route3, df8_route3, df9_route3, df10_route3, df11_route3]\n",
    "\n",
    "# 4th most popular route is route 2 from 212 --> 2622\n",
    "s = 532\n",
    "d = 2308\n",
    "df1_route4 = uber_df_1[uber_df_1['sourceid'] == s][uber_df_1['dstid'] == d]\n",
    "df1_route4['quarter'] = 'Q116'\n",
    "df2_route4 = uber_df_2[uber_df_2['sourceid'] == s][uber_df_2['dstid'] == d]\n",
    "df2_route4['quarter'] = 'Q216'\n",
    "df3_route4 = uber_df_3[uber_df_3['sourceid'] == s][uber_df_3['dstid'] == d]\n",
    "df3_route4['quarter'] = 'Q316'\n",
    "df4_route4 = uber_df_4[uber_df_4['sourceid'] == s][uber_df_4['dstid'] == d]\n",
    "df4_route4['quarter'] = 'Q416'\n",
    "df5_route4 = uber_df_5[uber_df_5['sourceid'] == s][uber_df_5['dstid'] == d]\n",
    "df5_route4['quarter'] = 'Q117'\n",
    "df6_route4 = uber_df_6[uber_df_6['sourceid'] == s][uber_df_6['dstid'] == d]\n",
    "df6_route4['quarter'] = 'Q217'\n",
    "df7_route4 = uber_df_7[uber_df_7['sourceid'] == s][uber_df_7['dstid'] == d]\n",
    "df7_route4['quarter'] = 'Q317'\n",
    "df8_route4 = uber_df_8[uber_df_8['sourceid'] == s][uber_df_8['dstid'] == d]\n",
    "df8_route4['quarter'] = 'Q417'\n",
    "df9_route4 = uber_df_9[uber_df_9['sourceid'] == s][uber_df_9['dstid'] == d]\n",
    "df9_route4['quarter'] = 'Q118'\n",
    "df10_route4 = uber_df_10[uber_df_10['sourceid'] == s][uber_df_10['dstid'] == d]\n",
    "df10_route4['quarter'] = 'Q218'\n",
    "df11_route4 = uber_df_11[uber_df_11['sourceid'] == d][uber_df_11['dstid'] == d]\n",
    "df11_route4['quarter'] = 'Q318'\n",
    "\n",
    "# condensed uber datasets (containing only the most popular route)\n",
    "dfs_route_4 = [df1_route4, df2_route4, df3_route4, df4_route4, df5_route4, df6_route4, df7_route4, df8_route4, df9_route4, df10_route4, df11_route4]\n",
    "\n",
    "# print out shape of each route \n",
    "for df_route in [dfs_route_1, dfs_route_2, dfs_route_3, dfs_route_4]:\n",
    "    for df in df_route:\n",
    "        print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop geometric mean columns: we are only interested in arithmetic means \n",
    "for df_route in [dfs_route_1, dfs_route_2, dfs_route_3, dfs_route_4]:\n",
    "    for df in df_route:\n",
    "        df.drop(columns=['geometric_mean_travel_time', 'geometric_standard_deviation_travel_time'], inplace=True)\n",
    "        print(df.head())\n",
    "        \n",
    "# describe the data \n",
    "for df_route in [dfs_route_1, dfs_route_2, dfs_route_3, dfs_route_4]:\n",
    "    for df in df_route:\n",
    "        print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route1_mean = pd.DataFrame(columns=['mean', 'quarter'])\n",
    "for df_route in dfs_route_1:\n",
    "    mean = df_route[\"mean_travel_time\"].mean()\n",
    "    quarter = df_route.iloc[0]\n",
    "    quarter = quarter['quarter']\n",
    "    route1_mean = route1_mean.append({'mean' : mean , 'quarter': quarter}, ignore_index=True)\n",
    "\n",
    "route2_mean = pd.DataFrame(columns=['mean', 'quarter'])\n",
    "for df_route in dfs_route_2:\n",
    "    mean = df_route[\"mean_travel_time\"].mean()\n",
    "    quarter = df_route.iloc[0]\n",
    "    quarter = quarter['quarter']\n",
    "    route2_mean = route1_mean.append({'mean' : mean , 'quarter': quarter}, ignore_index=True)\n",
    "\n",
    "route3_mean = pd.DataFrame(columns=['mean', 'quarter'])\n",
    "for df_route in dfs_route_3:\n",
    "    mean = df_route[\"mean_travel_time\"].mean()\n",
    "    quarter = df_route.iloc[0]\n",
    "    quarter = quarter['quarter']\n",
    "    route3_mean = route3_mean.append({'mean' : mean , 'quarter': quarter}, ignore_index=True)\n",
    "    \n",
    "route4_mean = pd.DataFrame(columns=['mean', 'quarter'])\n",
    "for df_route in dfs_route_4:\n",
    "    mean = df_route[\"mean_travel_time\"].mean()\n",
    "    quarter = df_route.iloc[0]\n",
    "    quarter = quarter['quarter']\n",
    "    route4_mean = route4_mean.append({'mean' : mean , 'quarter': quarter}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Route 1 change over travel time \n",
    "route1_mean.plot(kind='line', x='quarter', y='mean')\n",
    "plt.xticks(np.arange(0, 11, 1.0))\n",
    "plt.xticks(np.arange(11), ('Q116', 'Q216', 'Q316', 'Q416', 'Q117', 'Q217', 'Q317', 'Q417', 'Q118', 'Q218', 'Q318'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route2_mean.plot(kind='line', x='quarter', y='mean')\n",
    "plt.xticks(np.arange(0, 11, 1.0))\n",
    "plt.xticks(np.arange(11), ('Q116', 'Q216', 'Q316', 'Q416', 'Q117', 'Q217', 'Q317', 'Q417', 'Q118', 'Q218', 'Q318'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route3_mean.plot(kind='line', x='quarter', y='mean')\n",
    "plt.xticks(np.arange(0, 11, 1.0))\n",
    "plt.xticks(np.arange(11), ('Q116', 'Q216', 'Q316', 'Q416', 'Q117', 'Q217', 'Q317', 'Q417', 'Q118', 'Q218', 'Q318'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route4_mean.plot(kind='line', x='quarter', y='mean')\n",
    "plt.xticks(np.arange(0, 11, 1.0))\n",
    "plt.xticks(np.arange(11), ('Q116', 'Q216', 'Q316', 'Q416', 'Q117', 'Q217', 'Q317', 'Q417', 'Q118', 'Q218', 'Q318'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Upon visualizing the data, we saw that it would be more helpful to create a data frame based on seasons (quarters: 1-4) rather than looking at the progression throughout the years vs. mean travel time. In the following cells, we use the filtered data to find all routes in each dataset and combine different years with the same quarter under one column entry for each of the 4 quarters (seasons). \n",
    "\n",
    "Routes are determined as entries from the original data frame that have the same source and destination id. Our analysis is concerned with Uber travel times across different seasons, so the particular time of day the travel happened does not matter. Therefore, we can just take the average across hours of day for a particular route and add the entry to the dataframe accordingly. \n",
    "\n",
    "We can also drop the arithmatic mean, arithmatic standard deviation, geometric mean, and geometric standard deviation because we are just looking to find an average travel time for each particular route. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sourceid</th>\n",
       "      <th>dstid</th>\n",
       "      <th>hod</th>\n",
       "      <th>mean_travel_time</th>\n",
       "      <th>standard_deviation_travel_time</th>\n",
       "      <th>geometric_mean_travel_time</th>\n",
       "      <th>geometric_standard_deviation_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>94.68</td>\n",
       "      <td>144.07</td>\n",
       "      <td>63.02</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>222.60</td>\n",
       "      <td>151.05</td>\n",
       "      <td>191.21</td>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>19</td>\n",
       "      <td>450.27</td>\n",
       "      <td>195.81</td>\n",
       "      <td>423.50</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>9</td>\n",
       "      <td>1424.28</td>\n",
       "      <td>366.28</td>\n",
       "      <td>1379.41</td>\n",
       "      <td>1.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>1191.91</td>\n",
       "      <td>302.11</td>\n",
       "      <td>1159.90</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sourceid  dstid  hod  mean_travel_time  \\\n",
       "0           7         9     20   10             94.68   \n",
       "1          27         9     79    8            222.60   \n",
       "2          28         9     80   19            450.27   \n",
       "3          29         9     81    9           1424.28   \n",
       "4          33         9     98    7           1191.91   \n",
       "\n",
       "   standard_deviation_travel_time  geometric_mean_travel_time  \\\n",
       "0                          144.07                       63.02   \n",
       "1                          151.05                      191.21   \n",
       "2                          195.81                      423.50   \n",
       "3                          366.28                     1379.41   \n",
       "4                          302.11                     1159.90   \n",
       "\n",
       "   geometric_standard_deviation_travel_time  \n",
       "0                                      2.48  \n",
       "1                                      1.71  \n",
       "2                                      1.39  \n",
       "3                                      1.29  \n",
       "4                                      1.25  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in filtered data into the dataframe for quarter 1, 2016\n",
    "df1_loc = 'filtered_san_francisco-censustracts-2016-1-OnlyWeekdays-HourlyAggregate.csv'\n",
    "df1 = pd.read_csv(df1_loc)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sourceid</th>\n",
       "      <th>dstid</th>\n",
       "      <th>mean_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>94.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>79</td>\n",
       "      <td>222.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>450.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>1424.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>98</td>\n",
       "      <td>1191.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sourceid  dstid  mean_travel_time\n",
       "0         9     20             94.68\n",
       "1         9     79            222.60\n",
       "2         9     80            450.27\n",
       "3         9     81           1424.28\n",
       "4         9     98           1191.91"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns \n",
    "df1.drop(columns=['Unnamed: 0', 'hod', 'standard_deviation_travel_time', 'geometric_mean_travel_time', 'geometric_standard_deviation_travel_time'], inplace=True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to find each route \n",
    "\n",
    "def find_route(df, year):\n",
    "    # route_name : mean_travel_time (across all hours)\n",
    "    route_data = {}\n",
    "    for index, row in df.iterrows():\n",
    "        route_name = str(row['sourceid']) + '-' + str(row['dstid'])\n",
    "        if route_name not in route_data:\n",
    "            to_add = (row['mean_travel_time'], 1)\n",
    "            route_data[route_name] = to_add\n",
    "        else: \n",
    "            count = route_data[route_name][1] + 1\n",
    "            curr_sum = route_data[route_name][0] + row['mean_travel_time']\n",
    "            to_add = (curr_sum, count)\n",
    "            route_data[route_name] = to_add\n",
    "    # now find the mean time for each route \n",
    "    route_names = [] \n",
    "    route_times = [] \n",
    "    years = []\n",
    "    for route in route_data: \n",
    "        route_names.append(route)\n",
    "        route_info = route_data[route]\n",
    "        time = (route_info[0] / route_info[1])\n",
    "        route_times.append(time)\n",
    "        years.append(year)\n",
    "    new_df = pd.DataFrame(list(zip(route_names, route_times)), columns=['route_name', 'mean_travel_time'])\n",
    "    new_df['year'] = years\n",
    "    new_df.set_index('route_name')\n",
    "    return new_df \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original size\n",
      "1384290\n",
      "new size\n",
      "171615\n",
      "I eliminated this many rows:1212675\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_name</th>\n",
       "      <th>mean_travel_time</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0-20.0</td>\n",
       "      <td>99.581111</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0-79.0</td>\n",
       "      <td>195.021111</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0-80.0</td>\n",
       "      <td>444.638889</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0-81.0</td>\n",
       "      <td>1473.006667</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0-98.0</td>\n",
       "      <td>1761.753333</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0-113.0</td>\n",
       "      <td>725.247778</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.0-155.0</td>\n",
       "      <td>3621.330000</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0-165.0</td>\n",
       "      <td>406.264444</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0-80.0</td>\n",
       "      <td>497.136667</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0-81.0</td>\n",
       "      <td>1449.917778</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  route_name  mean_travel_time  year\n",
       "0   9.0-20.0         99.581111  2016\n",
       "1   9.0-79.0        195.021111  2016\n",
       "2   9.0-80.0        444.638889  2016\n",
       "3   9.0-81.0       1473.006667  2016\n",
       "4   9.0-98.0       1761.753333  2016\n",
       "5  9.0-113.0        725.247778  2016\n",
       "6  9.0-155.0       3621.330000  2016\n",
       "7  9.0-165.0        406.264444  2016\n",
       "8  20.0-80.0        497.136667  2016\n",
       "9  20.0-81.0       1449.917778  2016"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1_test = df1[:100]\n",
    "\n",
    "# this is the size before condensing into routes \n",
    "print('original size')\n",
    "orig_size = df1.size\n",
    "print(df1.size)\n",
    "\n",
    "df1 = find_route(df1, 2016)\n",
    "\n",
    "# this is the size of the new dataframe with routes condensed \n",
    "print('new size')\n",
    "print(df1.size)\n",
    "new_size = df1.size\n",
    "rows_eliminated = orig_size - new_size\n",
    "\n",
    "print('I eliminated this many rows: ' + str(rows_eliminated))\n",
    "df1.head(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_san_francisco-censustracts-2016-4-OnlyWeekdays-HourlyAggregate.csv \n",
      "original shape: (1258589, 8)\n",
      "new shape\n",
      "(163915, 3)\n",
      "I eliminated this many rows:4542611\n",
      "\n",
      "\n",
      "\n",
      "filtered_san_francisco-censustracts-2017-3-OnlyWeekdays-HourlyAggregate.csv \n",
      "original shape: (1525188, 8)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for root, dirs, files in os.walk(\"/Users/zoeychesny/Desktop/filtered_data\"):\n",
    "    cleaned_dfs = [] \n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = root + '/' + file\n",
    "            df = pd.read_csv(path)\n",
    "\n",
    "            print(file + \" \\noriginal shape: \" + str(df.shape))\n",
    "\n",
    "            #drop unnecessary columns \n",
    "            df.drop(columns=['hod', 'standard_deviation_travel_time', 'geometric_mean_travel_time', 'geometric_standard_deviation_travel_time'], inplace=True)\n",
    "            \n",
    "            \n",
    "            # this is the size before condensing into routes \n",
    "            orig_size = df.size\n",
    "            year = int(file[36:40])\n",
    "            quarter = int(file[41])\n",
    "\n",
    "            df = find_route(df, 2016)\n",
    "\n",
    "            # this is the size of the new dataframe with routes condensed \n",
    "            print('new shape')\n",
    "            print(df.shape)\n",
    "            new_size = df.size\n",
    "            rows_eliminated = orig_size - new_size\n",
    "\n",
    "            print('I eliminated this many rows:' + str(rows_eliminated))\n",
    "            print('\\n\\n')\n",
    "            \n",
    "            \n",
    "            df.to_csv(\"df_q\" + str(quarter) + \"_y\"+ str(year) + \".csv\")\n",
    "\n",
    "            cleaned_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find routes that are the same across all 11 quarters \n",
    "\n",
    "def route_matching(list_of_dfs):\n",
    "    base = list_of_dfs[0]\n",
    "    q1 = [0, 4, 8]\n",
    "    q2 = [1, 5, 9]\n",
    "    q3 = [2, 6, 10]\n",
    "    q4 = [3, 7]\n",
    "    all_routes = [] \n",
    "    q1_time = []\n",
    "    q2_time = [] \n",
    "    q3_time = [] \n",
    "    q4_time = [] \n",
    "    \n",
    "    quarters = [q1, q2, q3, q4]\n",
    "    q_time = [q1_time, q2_time, q3_time, q4_time]\n",
    "    \n",
    "    route_count = 0 \n",
    "    \n",
    "    # find 100 routes across the datasets \n",
    "    while route_count < 101: \n",
    "        for index, row in base.iterrows():\n",
    "            r_name = row['route_name']\n",
    "            # now check all the other dfs for this route\n",
    "            if is_route_in_all(r_name, list_of_dfs) == True:\n",
    "                all_routes.append(r_name)\n",
    "                route_count += 1 \n",
    "                q_num = 0 \n",
    "\n",
    "                # iterate for each quarter \n",
    "                for i in range(4):\n",
    "                    time_sum = 0 \n",
    "                    for j in quarters[i]:\n",
    "                        time_sum = time_sum + extract_route_time(list_of_dfs[j], r_name)\n",
    "                    time_mean = time_sum / len(quarters[i])\n",
    "                    q_time[i].append(time_mean)\n",
    "\n",
    "        new_df = pd.DataFrame(columns=['route_name', 'Q1_mean_travel_time', 'Q2_mean_travel_time', 'Q3_mean_travel_time', 'Q4_mean_travel_time'])\n",
    "        new_df['route_name'] = all_routes\n",
    "        new_df['Q1_mean_travel_time'] = q1_time\n",
    "        new_df['Q2_mean_travel_time'] = q2_time\n",
    "        new_df['Q3_mean_travel_time'] = q3_time\n",
    "        new_df['Q4_mean_travel_time'] = q4_time\n",
    "        return new_df\n",
    "    \n",
    "\n",
    "def is_route_in_all(route, list_of_dfs):\n",
    "    for df in list_of_dfs: \n",
    "        check = list(df['route_name'])\n",
    "        if route not in check:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# route_time\n",
    "def extract_route_time(df, route_name):\n",
    "    row = df.loc[df['route_name'] == route_name]\n",
    "    time_list = list(row['mean_travel_time'])\n",
    "    return float(time_list[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataframes from filtered data \n",
    "\n",
    "new_dfs = [] \n",
    "\n",
    "import os\n",
    "for root, dirs, files in os.walk(\"/Users/zoeychesny/Desktop/COGS-108-Final-Project\"):\n",
    "    cleaned_dfs = [] \n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            if file[0:2] == 'df':\n",
    "                path = root +\"/\"+ file\n",
    "                df = pd.read_csv(path)\n",
    "                df.drop(columns='Unnamed: 0', inplace=True)\n",
    "                new_dfs.append(df)\n",
    "                \n",
    "is_route_in_all('9.0-44.0', new_dfs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_name</th>\n",
       "      <th>Q1_mean_travel_time</th>\n",
       "      <th>Q2_mean_travel_time</th>\n",
       "      <th>Q3_mean_travel_time</th>\n",
       "      <th>Q4_mean_travel_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [route_name, Q1_mean_travel_time, Q2_mean_travel_time, Q3_mean_travel_time, Q4_mean_travel_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allquarter_df = route_matching(new_dfs)\n",
    "print(allquarter_df.size)\n",
    "allquarter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include cells that describe the steps in your data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function that changes the quarter names to numeric values from 1-11, 1 being the earliest quarter and 11 being the latest, so they can be used for multiple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_quarter(quarter):\n",
    "\n",
    "    quarter = quarter.lower()\n",
    "    \n",
    "    quarter = quarter.strip()\n",
    "    \n",
    "    quarter = quarter.replace('q', '')\n",
    "    quarter = quarter.replace('116', '1')\n",
    "    quarter = quarter.replace('216', '2')\n",
    "    quarter = quarter.replace('316', '3')\n",
    "    quarter = quarter.replace('416', '4')\n",
    "    quarter = quarter.replace('117', '5')\n",
    "    quarter = quarter.replace('217', '6')\n",
    "    quarter = quarter.replace('317', '7')\n",
    "    quarter = quarter.replace('417', '8')\n",
    "    quarter = quarter.replace('118', '9')\n",
    "    quarter = quarter.replace('218', '10')\n",
    "    quarter = quarter.replace('318', '11')\n",
    "    \n",
    "    quarter = quarter.strip()\n",
    "    \n",
    "    return int(quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function to data for all 4 routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_route in dfs_route_1:\n",
    "    df_route['quarter'] = df_route['quarter'].apply(standardize_quarter)\n",
    "for df_route in dfs_route_2:\n",
    "    df_route['quarter'] = df_route['quarter'].apply(standardize_quarter)\n",
    "for df_route in dfs_route_3:\n",
    "    df_route['quarter'] = df_route['quarter'].apply(standardize_quarter)\n",
    "for df_route in dfs_route_4:\n",
    "    df_route['quarter'] = df_route['quarter'].apply(standardize_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use linear models to check if there is a significant difference in mean drive time during each quarter over each route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df_route in dfs_route_1:\n",
    "    outcome_route1, predictors_route1 = patsy.dmatrices('quarter ~ mean_travel_time', df_route)\n",
    "    mod_route1 = sm.OLS(outcome_route1, predictors_route1)\n",
    "    res_route1 = mod_route1.fit()\n",
    "\n",
    "    p_value1 = res_route1.pvalues[1]\n",
    "    \n",
    "    if p_value1 < 0.01:\n",
    "        print('There is a significant difference in mean drive time over route 1 during quarter', df_route['quarter'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_route in dfs_route_2:\n",
    "    outcome_route2, predictors_route2 = patsy.dmatrices('quarter ~ mean_travel_time', df_route)\n",
    "    mod_route2 = sm.OLS(outcome_route2, predictors_route2)\n",
    "    res_route2 = mod_route2.fit()\n",
    "\n",
    "    p_value2 = res_route2.pvalues[1]\n",
    "    \n",
    "    if p_value2 < 0.01:\n",
    "        print('There is a significant difference in mean drive time over route 2 during quarter', df_route['quarter'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_route in dfs_route_3:\n",
    "    outcome_route3, predictors_route3 = patsy.dmatrices('quarter ~ mean_travel_time', df_route)\n",
    "    mod_route3 = sm.OLS(outcome_route3, predictors_route3)\n",
    "    res_route3 = mod_route3.fit()\n",
    "\n",
    "    p_value3 = res_route3.pvalues[1]\n",
    "    \n",
    "    if p_value3 < 0.01:\n",
    "        print('There is a significant difference in mean drive time over route 3 during quarter', df_route['quarter'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_route in dfs_route_4:\n",
    "    outcome_route4, predictors_route4 = patsy.dmatrices('quarter ~ mean_travel_time', df_route)\n",
    "    mod_route4 = sm.OLS(outcome_route4, predictors_route4)\n",
    "    res_route4 = mod_route4.fit()\n",
    "\n",
    "    p_value4 = res_route4.pvalues[1]\n",
    "    \n",
    "    if p_value4 < 0.01:\n",
    "        print('There is a significant difference in mean drive time over route 4 during quarter', df_route['quarter'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your ethics & privacy discussion here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Fill in your discussion information here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
